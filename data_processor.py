import numpy as np
import json
import glob
import copy


def read_label_csv(path):
    label_table = dict()
    with open(path, "r", encoding='ISO-8859-1') as f:
        for line in f.readlines()[1:]:
            fname, label = line.strip().split(",")
            label_table[fname] = int(label)
    return label_table


def read_json(path):
    with open(path, "r") as f:
        return json.load(f)


class PeminerParser:
    def __init__(self, path):
        self.report = read_json(path)
        self.vector = []

    def process_report(self):
        '''
            전체 데이터 사용
        '''

        self.vector = [value for _, value in sorted(self.report.items(), key=lambda x: x[0])]
        return self.vector


class EmberParser:
    '''
        예제에서 사용하지 않은 특징도 사용하여 벡터화 할 것을 권장
    '''

    def __init__(self, path):
        self.report = read_json(path)
        self.vector = []

    def get_histogram_info(self):
        histogram = np.array(self.report["histogram"])
        total = histogram.sum()
        vector = histogram / total
        return vector.tolist()

    def get_string_info(self):
        strings = self.report["strings"]

        hist_divisor = float(strings['printables']) if strings['printables'] > 0 else 1.0
        vector = [
            strings['numstrings'],
            strings['avlength'],
            strings['printables'],
            strings['entropy'],
            strings['paths'],
            strings['urls'],
            strings['registry'],
            strings['MZ']
        ]
        vector += (np.asarray(strings['printabledist']) / hist_divisor).tolist()
        return vector

    def get_general_file_info(self):
        general = self.report["general"]
        vector = [
            general['size'], general['vsize'], general['has_debug'], general['exports'], general['imports'],
            general['has_relocations'], general['has_resources'], general['has_signature'], general['has_tls'],
            general['symbols']
        ]
        return vector

    def process_report(self):
        vector = []
        vector += self.get_general_file_info()
        vector += self.get_histogram_info()
        vector += self.get_string_info()
        '''
            특징 추가
        '''
        return vector


class PestudioParser:
    '''
        사용할 특징을 선택하여 벡터화 할 것을 권장
    '''

    def __init__(self, path):
        self.report = read_json(path)
        self.vector = []

    def process_report(self):
        ret = []

        vir = self.report["image"]["virustotal"]
        if vir != "offline" and vir != "n/a":
            ret.append(int(vir["@detection"]))
        else:
            ret.append(0)
        
        return ret


def get_train_path(petype: str):
    checker = set()
    checker.add("EMBER")
    checker.add("PEMINER")
    checker.add("PESTUDIO")
    if petype not in checker:
        print("Invalid path!")
        return

    return f"데이터/{petype}/학습데이터/"


def get_valid_path(petype: str):
    checker = set()
    checker.add("EMBER")
    checker.add("PEMINER")
    checker.add("PESTUDIO")
    if petype not in checker:
        print("Invalid path!")
        return

    return f"데이터/{petype}/검증데이터/"


def get_test_path(petype: str):
    checker = set()
    checker.add("EMBER")
    checker.add("PEMINER")
    checker.add("PESTUDIO")
    if petype not in checker:
        print("Invalid path!")
        return

    return f"데이터/{petype}/테스트데이터/"


def process_dataset(datatype: str):
    basepath = ""
    labels = None

    if datatype == "TRAIN":
        labels = read_label_csv("데이터/학습데이터_정답.csv")
        basepath = get_train_path("PEMINER")
    elif datatype == "VALID":
        labels = read_label_csv("데이터/검증데이터_정답.csv")
        basepath = get_valid_path("PEMINER")
    else:
        print("레이블이 없는 데이터입니다.")
        return dict()

    datadict = dict()

    for fname in glob.glob(basepath + '*'):
        # Erase ".json"
        key = fname[:-5].split('/')[-1]
        # Insert feature vector
        datadict[key] = copy.deepcopy(PeminerParser(fname).process_report())

    if datatype == "TRAIN":
        basepath = get_train_path("EMBER")
    else:
        basepath = get_valid_path("EMBER")

    for fname in glob.glob(basepath + '*'):
        key = fname[:-5].split('/')[-1]
        datadict[key] += EmberParser(fname).process_report()

    # TODO: Handle the pestudio
    if datatype == "TRAIN":
        basepath = get_train_path("PESTUDIO")
    else:
        basepath = get_valid_path("PESTUDIO")

    ret = dict()
    ret["data_names"] = list()
    ret["data"] = []
    ret["target"] = np.array([], dtype=np.uint8)
    for key in labels.keys():
        ret["data_names"].append(key)
        ret["data"].append(datadict[key])
        ret["target"] = np.append(ret["target"], labels[key])
    ret["data"] = np.array(ret["data"])
    return ret
